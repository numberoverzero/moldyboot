#!/usr/bin/env python

import logging
import rq

from config import api_endpoint, session, key_manager, user_manager, queue
from gaas.tasks import RedisContext

logger = logging.getLogger(__name__)

# Inject dependencies for worker threads =============================================================================
RedisContext.initialize(user_manager, key_manager, session, api_endpoint)


# Retries ============================================================================================================
# https://gist.github.com/spjwebster/6521272
MAX_FAILURES = 3


def retry_handler(job, *exc_info):
    job.meta.setdefault('failures', 0)
    job.meta['failures'] += 1

    # Too many failures
    if job.meta['failures'] >= MAX_FAILURES:
        logger.warn('job %s: failed too many times times - moving to failed queue' % job.id)
        job.save()
        return True

    # Requeue job and stop it from being moved into the failed queue
    logger.warn('job %s: failed %d times - retrying' % (job.id, job.meta['failures']))

    if queue.name == job.origin:
        queue.enqueue_job(job)
        return False

    # Can't find queue, which should basically never happen as we only work jobs that match the given queue names and
    # queues are transient in rq.
    logger.warn('job %s: cannot find queue %s - moving to failed queue' % (job.id, job.origin))
    return True


with rq.Connection():
    worker = rq.Worker([queue])
    worker.push_exc_handler(retry_handler)
    worker.work()
